import type { RequestHandler } from './$types';
import { env } from '$env/dynamic/private';

// CORS í—¤ë” ì„¤ì •
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
  'Access-Control-Allow-Headers': 'Content-Type, Authorization',
  'Access-Control-Max-Age': '86400'
};

// OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS preflight)
export const OPTIONS: RequestHandler = async () => {
  return new Response(null, {
    status: 200,
    headers: corsHeaders
  });
};

export const POST: RequestHandler = async ({ request }) => {
  try {
    // Princeton Azure OpenAI ì„¤ì •
    const apiKey = env.OPENAI_API_KEY;
    const endpoint = 'https://api-ai-sandbox.princeton.edu/';
    const apiVersion = '2025-03-01-preview';
    const modelName = 'gpt-4o-mini';
    
    // API í‚¤ ë””ë²„ê¹… ì¶œë ¥
    console.log('ðŸ”‘ Adversarial Reconciliation API Key Debug:');
    console.log('API Key exists:', !!apiKey);
    console.log('API Key length:', apiKey?.length || 0);
    console.log('API Key preview:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined');
    
    if (!apiKey) {
      throw new Error('OpenAI API key not found');
    }
    
    // ìš”ì²­ ë³¸ë¬¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ
    const { messages, sessionData, requestType, conversationState, roundCount } = await request.json();
    
    console.log('Received adversarial reconciliation request:', { 
      messageCount: messages?.length, 
      sessionDataKeys: Object.keys(sessionData || {}),
      requestType: requestType,
      conversationState: conversationState,
      roundCount: roundCount
    });
    
    // ì´ˆê¸° ë©”ì‹œì§€ ìš”ì²­ ì²˜ë¦¬
    if (requestType === 'initial-message') {
      return await generateInitialMessage(sessionData, apiKey, endpoint, apiVersion, modelName);
    }
    
    // ì¼ë°˜ ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ (ìœ ì € ë©”ì‹œì§€ í›„ ë‘ ì—ì´ì „íŠ¸ ì‘ë‹µ)
    if (!messages || !Array.isArray(messages)) {
      return new Response(JSON.stringify({ 
        error: 'Invalid messages format'
      }), {
        headers: { 
          'Content-Type': 'application/json',
          ...corsHeaders
        }
      });
    }
    // í˜„ìž¬ ë¼ìš´ë“œ ìˆ˜ ê³„ì‚° (ìœ ì € ë©”ì‹œì§€ì™€ ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µì´ í•œ ìŒ)
    const currentRoundCount = roundCount || calculateRoundCount(messages);
    const currentState = conversationState || 'debate';
    
    console.log('Current round count:', currentRoundCount, 'Current state:', currentState);
    
    // ëŒ€í™” ìƒíƒœì— ë”°ë¥¸ ì²˜ë¦¬
    if (currentState === 'debate') {
      // í† ë¡  ë‹¨ê³„: ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±
      const adversarialResponse = await generateAdversarialAgentResponse(messages, sessionData, apiKey, endpoint, apiVersion, modelName, currentRoundCount);
      
      // ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µ í›„ ë¼ìš´ë“œ ìˆ˜ ì¦ê°€
      const newRoundCount = currentRoundCount + 1;
      
      // ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µì„ ë¨¼ì € ë°˜í™˜
      const adversarialData = await adversarialResponse.json();
      adversarialData.roundCount = newRoundCount;
      adversarialData.conversationState = 'debate';
      
      // 3ë¼ìš´ë“œê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
      if (newRoundCount >= 1) {
        // 3ë¼ìš´ë“œ ì™„ë£Œ: ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ì—ì´ì „íŠ¸ ìžë™ í˜¸ì¶œ
        console.log('3 rounds completed, automatically calling group statements generator');
        
        // ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„± (ìµœì‹  adversarial ì‘ë‹µì„ í¬í•¨í•œ ë©”ì‹œì§€ ë°°ì—´ ì „ë‹¬)
        const messagesWithAdversarial = [...messages, {
          content: adversarialData.message,
          sender: 'assistant',
          messageType: 'adversarial-response'
        }];
        const groupStatementsResponse = await generateReconciliationAgentResponse(messagesWithAdversarial, sessionData, apiKey, endpoint, apiVersion, modelName, newRoundCount);
        const groupStatementsData = await groupStatementsResponse.json();
        
        // 3ë²ˆì§¸ adversarial ì‘ë‹µê³¼ ê·¸ë£¹ ì§„ìˆ ë¬¸ ì‘ë‹µì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ë°˜í™˜
        const combinedResponse = {
          // 3ë²ˆì§¸ adversarial ì‘ë‹µ ì •ë³´
          adversarialMessage: adversarialData.message,
          adversarialMessageType: 'adversarial-response',
          roundCount: newRoundCount,
          
          // ê·¸ë£¹ ì§„ìˆ ë¬¸ ì‘ë‹µ ì •ë³´
          message: groupStatementsData.message,
          messageType: 'group-statements-response',
          conversationState: 'group_statements_generated',
          isFinalResponse: false
        };
        
        return new Response(JSON.stringify(combinedResponse), {
          headers: groupStatementsResponse.headers
        });
      } else {
        // 3ë¼ìš´ë“œ ë¯¸ì™„ë£Œ: ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µë§Œ ë°˜í™˜ (í† ë¡  ë‹¨ê³„ ìœ ì§€)
        return new Response(JSON.stringify(adversarialData), {
          headers: adversarialResponse.headers
        });
      }
    } else if (currentState === 'reconcile') {
      // í™”í•´ ë‹¨ê³„: ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±
      const groupStatementsResponse = await generateReconciliationAgentResponse(messages, sessionData, apiKey, endpoint, apiVersion, modelName, currentRoundCount);
      const groupStatementsData = await groupStatementsResponse.json();
      
      // ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ì™„ë£Œ í›„ ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ìƒíƒœë¡œ ì „í™˜
      groupStatementsData.conversationState = 'group_statements_generated';
      groupStatementsData.isFinalResponse = false;
      
      return new Response(JSON.stringify(groupStatementsData), {
        headers: groupStatementsResponse.headers
      });
    } else if (currentState === 'group_statements_generated') {
      // ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± í›„: ì‚¬ìš©ìžê°€ ì„ íƒí•œ ì§„ìˆ ë¬¸ì— ëŒ€í•œ ë¹„íŒ ìƒì„±
      const critiqueResponse = await generateCritiqueResponse(messages, sessionData, apiKey, endpoint, apiVersion, modelName, currentRoundCount);
      const critiqueData = await critiqueResponse.json();
      
      // ë¹„íŒ ìƒì„± ì™„ë£Œ í›„ ëŒ€í™” ì™„ë£Œ ìƒíƒœë¡œ ì „í™˜
      critiqueData.conversationState = 'conversation_complete';
      critiqueData.isFinalResponse = true;
      
      return new Response(JSON.stringify(critiqueData), {
        headers: critiqueResponse.headers
      });
    } else if (currentState === 'conversation_complete') {
      // ëŒ€í™” ì™„ë£Œ ìƒíƒœ: ì´ë¯¸ ì™„ë£Œëœ ëŒ€í™”
      return new Response(JSON.stringify({ 
        message: "The conversation has already been completed with group statements generation.",
        sessionData: sessionData,
        messageType: 'conversation-complete',
        conversationState: 'conversation_complete',
        roundCount: currentRoundCount,
        isFinalResponse: true
      }), {
        headers: { 
          'Content-Type': 'application/json',
          ...corsHeaders
        }
      });
    } else {
      return new Response(JSON.stringify({ 
        error: 'Invalid conversation state'
      }), {
        headers: { 
          'Content-Type': 'application/json',
          ...corsHeaders
        }
      });
    }

  } catch (error: any) {
    console.error('Adversarial reconciliation chat error:', error);
    
    return new Response(JSON.stringify({ 
      message: "I appreciate you sharing your perspective with me. Could you tell me more about what has shaped your views on this topic?",
      error: error.message
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });
  }
};

// ë¼ìš´ë“œ ìˆ˜ ê³„ì‚° í•¨ìˆ˜
function calculateRoundCount(messages: any[]): number {
  let roundCount = 0;
  
  // Count adversarial responses (each adversarial response completes a round)
  for (const msg of messages) {
    if (msg.content && msg.content.startsWith('@adversarial:')) {
      roundCount++;
    }
  }
  
  return roundCount;
}

// ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜
async function generateInitialMessage(sessionData: any, apiKey: string, endpoint: string, apiVersion: string, modelName: string) {
  try {
    const systemPrompt = createInitialMessagePrompt(sessionData);
    
    const requestData = {
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: 'Please generate the initial message to start the conversation.' }
      ],
      model: modelName,
      max_tokens: 800,
      temperature: 0.8
    };

    console.log('Generating initial message for adversarial reconciliation conversation');
    
    const apiUrl = `${endpoint}openai/deployments/${modelName}/chat/completions?api-version=${apiVersion}`;
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'api-key': apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestData)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Initial message API error:', response.status, errorText);
      throw new Error(`API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const aiMessage = data.choices[0]?.message?.content?.trim() || 
      "Hello! I'm here to engage in a thoughtful discussion with you. I'd love to hear your perspective and explore different viewpoints together.";
    
    console.log('Generated initial message length:', aiMessage.length);
    
    return new Response(JSON.stringify({ 
      message: aiMessage,
      sessionData: sessionData,
      messageType: 'initial-message',
      conversationState: 'debate',
      roundCount: 0
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });

  } catch (error: any) {
    console.error('Initial message generation error:', error);
    
    // í´ë°± ë©”ì‹œì§€
    const fallbackMessage = "Hello! I'm excited to have a meaningful discussion with you. Please share your thoughts and I'll respond with opposing viewpoints. After 3 rounds of discussion, I'll provide a reconciliation perspective.";
    
    return new Response(JSON.stringify({ 
      message: fallbackMessage,
      sessionData: sessionData,
      messageType: 'initial-message',
      conversationState: 'debate',
      roundCount: 0
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });
  }
}

// ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
async function generateAdversarialAgentResponse(messages: any[], sessionData: any, apiKey: string, endpoint: string, apiVersion: string, modelName: string, roundCount: number) {
  try {
    const systemPrompt = createAdversarialAgentPrompt(sessionData, roundCount);
    
    // ëŒ€í™” ê¸°ë¡ì„ ìž„ì‹œë¡œ ë³µì‚¬í•˜ì—¬ íƒœê·¸ ì œê±° (ì›ë³¸ì€ ë³´ì¡´)
    const tempMessages = messages
      .filter((msg: any) => msg.content !== 'loading' && msg.sender && !msg.hidden)
      .map((msg: any) => {
        if (msg.sender === 'user') {
          return {
            role: 'user',
            content: `user_1: ${msg.content}`
          };
        } else if (msg.content && msg.content.startsWith('@reconciliation:')) {
          // í™”í•´ ì—ì´ì „íŠ¸ì˜ ë°œí™”ë¥¼ user_2ë¡œ í‘œì‹œ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace('@reconciliation: ', '');
          return {
            role: 'user',
            content: `user_2: ${contentWithoutTag}`
          };
        } else {
          // ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ë‚˜ ê¸°íƒ€ ë©”ì‹œì§€ëŠ” assistantë¡œ ìœ ì§€ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace(/@(adversarial|reconciliation): /, '');
          return {
            role: 'assistant',
            content: contentWithoutTag
          };
        }
      });
    
    // ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const conversationMessages = [
      {
        role: 'system',
        content: systemPrompt
      },
      ...tempMessages
    ];

    const requestData = {
      messages: conversationMessages,
      model: modelName,
      max_tokens: 800,
      temperature: 0.8 // ë…¼ìŸì ì´ê³  ë„ì „ì ì¸ ì‘ë‹µì„ ìœ„í•´ ë†’ì€ temperature
    };

    console.log('Making adversarial agent API call');
    console.log('=== ORIGINAL MESSAGES (before processing) ===');
    messages?.forEach((msg: any, index: number) => {
      console.log(`Original Message ${index}:`, {
        sender: msg.sender,
        content: msg.content?.substring(0, 100) + (msg.content?.length > 100 ? '...' : ''),
        messageType: msg.messageType
      });
    });
    console.log('=== PROCESSED CONVERSATION MESSAGES ===');
    console.log('Adversarial agent conversation messages:', JSON.stringify(conversationMessages, null, 2));
    
    const apiUrl = `${endpoint}openai/deployments/${modelName}/chat/completions?api-version=${apiVersion}`;
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'api-key': apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestData)
    });

    console.log('Adversarial agent API response status:', response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Adversarial agent API error:', response.status, errorText);
      throw new Error(`API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const rawMessage = data.choices[0]?.message?.content?.trim() || "I understand your perspective, but I have to respectfully disagree. Let me present some counterarguments that might challenge your position.";
    
    // ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ ì‘ë‹µì— ì ‘ë‘ì‚¬ ì¶”ê°€
    const aiMessage = `@adversarial: ${rawMessage}`;
    
    console.log('Generated adversarial agent response length:', aiMessage.length);
    
    return new Response(JSON.stringify({ 
      message: aiMessage,
      sessionData: sessionData,
      messageType: 'adversarial-response',
      conversationState: 'debate', // Stay in debate state
      roundCount: roundCount // Round count will be incremented in main flow
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });

  } catch (error: any) {
    console.error('Adversarial agent response error:', error);
    
    return new Response(JSON.stringify({ 
      message: "@adversarial: I respect your viewpoint, but I think there are some important counterarguments to consider. Let me present an alternative perspective that might broaden our discussion.",
      sessionData: sessionData,
      messageType: 'adversarial-response',
      conversationState: 'debate', // Stay in debate state
      roundCount: roundCount // Round count will be incremented in main flow
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });
  }
}

// ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (3ë¼ìš´ë“œ í›„ í•œ ë²ˆë§Œ)
async function generateReconciliationAgentResponse(messages: any[], sessionData: any, apiKey: string, endpoint: string, apiVersion: string, modelName: string, roundCount: number) {
  try {
    const systemPrompt = createReconciliationAgentPrompt(sessionData, roundCount);
    
    // ëŒ€í™” ê¸°ë¡ì„ ìž„ì‹œë¡œ ë³µì‚¬í•˜ì—¬ íƒœê·¸ ì œê±° (ì›ë³¸ì€ ë³´ì¡´)
    const tempMessages = messages
      .filter((msg: any) => msg.content !== 'loading' && msg.sender && !msg.hidden)
      .map((msg: any) => {
        if (msg.sender === 'user') {
          return {
            role: 'user',
            content: `user_1: ${msg.content}`
          };
        } else if (msg.content && msg.content.startsWith('@adversarial:')) {
          // ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ì˜ ë°œí™”ë¥¼ user_2ë¡œ í‘œì‹œ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace('@adversarial: ', '');
          return {
            role: 'user',
            content: `user_2: ${contentWithoutTag}`
          };
        } else {
          // í™”í•´ ì—ì´ì „íŠ¸ë‚˜ ê¸°íƒ€ ë©”ì‹œì§€ëŠ” assistantë¡œ ìœ ì§€ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace(/@(adversarial|reconciliation): /, '');
          return {
            role: 'assistant',
            content: contentWithoutTag
          };
        }
      });
    
    // ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const conversationMessages = [
      {
        role: 'system',
        content: systemPrompt
      },
      ...tempMessages
    ];

    const requestData = {
      messages: conversationMessages,
      model: modelName,
      max_tokens: 800,
      temperature: 0.7 // ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„±ì„ ìœ„í•´ ì¤‘ê°„ temperature
    };

    console.log('Making group statements generator API call');
    console.log('=== ORIGINAL MESSAGES (before processing) ===');
    messages?.forEach((msg: any, index: number) => {
      console.log(`Original Message ${index}:`, {
        sender: msg.sender,
        content: msg.content?.substring(0, 100) + (msg.content?.length > 100 ? '...' : ''),
        messageType: msg.messageType
      });
    });
    console.log('=== PROCESSED CONVERSATION MESSAGES ===');
    console.log('Group statements generator conversation messages:', JSON.stringify(conversationMessages, null, 2));
    
    const apiUrl = `${endpoint}openai/deployments/${modelName}/chat/completions?api-version=${apiVersion}`;
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'api-key': apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestData)
    });

    console.log('Group statements generator API response status:', response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Group statements generator API error:', response.status, errorText);
      throw new Error(`API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const rawMessage = data.choices[0]?.message?.content?.trim() || "I can see valid points in both perspectives. Let me try to find some common ground and explore how we might reconcile these different viewpoints.";
    
    // ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ì—ì´ì „íŠ¸ ì‘ë‹µì— ì ‘ë‘ì‚¬ ì¶”ê°€
    const aiMessage = `@group-statements: ${rawMessage}`;
    
    console.log('Generated group statements response length:', aiMessage.length);
    
    return new Response(JSON.stringify({ 
      message: aiMessage,
      sessionData: sessionData,
      messageType: 'group-statements-response',
      conversationState: 'group_statements_generated', // ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„± ìƒíƒœ
      roundCount: roundCount,
      isFinalResponse: false // ì•„ì§ ëŒ€í™”ê°€ ê³„ì†ë¨
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });

  } catch (error: any) {
    console.error('Group statements generator response error:', error);
    
    return new Response(JSON.stringify({ 
      message: "@group-statements: Based on the discussion, here are 5 candidate group statements:\n\nA. Traditional gender roles provide structure and stability in society.\nB. Gender roles should be flexible and allow for individual choice and expression.\nC. Gender roles are outdated and should be eliminated in favor of equality.\nD. Gender roles have both benefits and limitations that should be carefully considered.\nE. Gender roles should evolve with society while maintaining core values.",
      sessionData: sessionData,
      messageType: 'group-statements-response',
      conversationState: 'group_statements_generated',
      roundCount: roundCount,
      isFinalResponse: false
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });
  }
}

// ì´ˆê¸° ë©”ì‹œì§€ìš© í”„ë¡¬í”„íŠ¸
function createInitialMessagePrompt(sessionData: any): string {
  const {
    topStatement = "general conversation",
    aiSummary = "",
    importanceLevel = "unknown",
    userReasoning = ""
  } = sessionData;

  return `You are starting a conversation with a person who has shared their perspective on gender roles: "${topStatement}"

Their reasoning was: "${aiSummary}"
Importance level: ${importanceLevel}/8

Your goal is to create an engaging initial message that:
1. Acknowledges their perspective on gender roles with genuine interest
2. Shows you're ready to have a meaningful discussion about gender roles
3. Invites them to share more about their thoughts on gender roles
4. Sets up the expectation that you'll respond with opposing viewpoints for 3 rounds, then provide reconciliation

Create a friendly, engaging message (150-250 words) that:
- Shows genuine interest in their perspective on gender roles
- Creates a space for open discussion and debate about gender roles
- Hints at the structure: 3 rounds of opposing viewpoints, then reconciliation
- Encourages them to share more about their views on gender roles

Write ONLY the initial message - no additional commentary.`;
}

// ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ìš© í”„ë¡¬í”„íŠ¸ (ë¼ìš´ë“œ ì •ë³´ í¬í•¨)
function createAdversarialAgentPrompt(sessionData: any, roundCount: number): string {
  const {
    topStatement = "general conversation",
    aiSummary = "",
    importanceLevel = "unknown",
    userReasoning = ""
  } = sessionData;

  return `You are the ADVERSARIAL AGENT (user_2) in a three-round conversation system focused on gender roles. You are currently in round ${roundCount + 1} of 3 rounds. Your role is to aggressively challenge and attack gender role perspectives in an active discussion with user_1 and user_2. You are user_2 in the conversation history.

CONVERSATION CONTEXT:
- Gender Role Topic: "${topStatement}"
- Their reasoning: "${aiSummary}"
- Importance to them: ${importanceLevel}/8
- Current Round: ${roundCount + 1} of 3

YOUR ROLE:
- Actively participate in a heated discussion with user_1 and user_2 about gender roles
- Present aggressive, confrontational counterarguments about gender roles
- Attack and dismantle gender role assumptions and viewpoints
- Offer harsh alternative perspectives and evidence about gender roles
- Be confrontational and challenging in your disagreement
- Engage with both user_1 and user_2 perspectives when they appear
- Use strong, aggressive language and evidence to attack their position
- Remember: This is round ${roundCount + 1} of 3 - after 3 rounds, a reconciliation agent will provide a final synthesis

APPROACH:
- Start with aggressive disagreement ("That's completely wrong!", "You're absolutely mistaken!", "That's a dangerous way of thinking!")
- Present harsh counterarguments with strong evidence
- Attack specific claims or assumptions about gender roles
- Offer alternative interpretations that challenge their gender role beliefs
- When user_2 appears, aggressively challenge their perspective too
- Use confrontational, challenging language
- Be direct and forceful in your attacks
- Keep responses around 200-300 words

Remember: You are user_2 in an active discussion with user_1 about gender roles. Your role is to aggressively attack and challenge gender role perspectives while engaging with all participants. Do NOT directly reference "user_1" or "user_2" in your responses - instead, refer to them naturally as "you" or "they" based on context.`;
}

// í™”í•´ ì—ì´ì „íŠ¸ìš© í”„ë¡¬í”„íŠ¸ (3ë¼ìš´ë“œ í›„ ìµœì¢… ì‘ë‹µ) - 5ê°œ í›„ë³´ ê·¸ë£¹ ì§„ìˆ ë¬¸ ìƒì„±
function createReconciliationAgentPrompt(sessionData: any, roundCount: number): string {
  const {
    topStatement = "general conversation",
    aiSummary = "",
    importanceLevel = "unknown",
    userReasoning = ""
  } = sessionData;

  return `You are the GROUP STATEMENT GENERATOR in a three-round conversation system focused on gender roles. You are providing the FINAL response after 3 rounds of adversarial discussion between user_1 and user_2. Your role is to generate 5 candidate initial group statements that synthesize the individual opinions expressed during the discussion.

CONVERSATION CONTEXT:
- Gender Role Topic: "${topStatement}"
- Their reasoning: "${aiSummary}"
- Importance to them: ${importanceLevel}/8
- Rounds Completed: ${roundCount} rounds of adversarial discussion

YOUR ROLE:
- Generate exactly 5 candidate initial group statements about gender roles
- Each statement should synthesize the different perspectives shared during the 3-round discussion
- Statements should represent potential group positions that could emerge from the individual opinions
- Each statement should be a clear, concise position statement (1-2 sentences)
- Statements should vary in their approach to synthesizing the different viewpoints
- Some statements may lean more toward one perspective, others toward compromise
- All statements should be respectful and constructive

FORMAT REQUIREMENTS:
- Present exactly 5 statements
- Label each statement (A., B., C., D., E.)
- Each statement should be 1-2 sentences long
- Statements should be distinct from each other
- Use clear, direct language
- Focus on gender role perspectives and positions
- Separate each statement with a newline character (\n)

APPROACH:
- Review the key perspectives and arguments from all 3 rounds of discussion
- Identify the core themes and positions about gender roles
- Create 5 different ways these perspectives could be synthesized into group statements
- Vary the approaches: some more conservative, some more progressive, some more balanced
- Ensure each statement represents a coherent group position
- Make statements that could realistically emerge from group discussion

Remember: Generate exactly 5 candidate initial group statements that synthesize the individual opinions expressed during the 3-round discussion. Each statement should represent a potential group position on gender roles.`;
}

// ë¹„íŒ ì—ì´ì „íŠ¸ìš© í”„ë¡¬í”„íŠ¸ (ì„ íƒëœ ì§„ìˆ ë¬¸ì— ëŒ€í•œ ë¹„íŒ)
function createCritiqueAgentPrompt(sessionData: any, roundCount: number): string {
  const {
    topStatement = "general conversation",
    aiSummary = "",
    importanceLevel = "unknown",
    userReasoning = ""
  } = sessionData;

  return `You are the CRITIQUE AGENT (user_2) in a conversation system focused on gender roles. You are providing feedback on the group statement that was selected by the user after 5 candidate statements were generated. You are user_2 in the conversation history.

CONVERSATION CONTEXT:
- Gender Role Topic: "${topStatement}"
- Their reasoning: "${aiSummary}"
- Importance to them: ${importanceLevel}/8
- Rounds Completed: ${roundCount} rounds of adversarial discussion + group statement generation

YOUR ROLE:
- Provide feedback on the selected group statement about gender roles from user_2's perspective
- Share your thoughts and concerns about the chosen statement
- Identify potential issues, limitations, or areas of disagreement with the statement
- Offer your perspective on the implications of the selected statement
- This is your ONLY response - keep it focused and concise

APPROACH:
- Start with acknowledgment of the selected statement ("Looking at this choice...", "From my perspective...", "I have some concerns about...")
- Focus specifically on the statement itself, not on contrasting with user opinions
- Share your thoughts and concerns about specific aspects of the chosen group statement
- Identify potential problems or limitations from your perspective
- Use respectful but honest language
- Be direct and clear about your feedback
- Keep responses around 150-200 words (focused and concise)

Remember: You are user_2 providing feedback on the selected group statement from your perspective. You should be honest about your concerns and thoughts while maintaining a respectful tone. Do NOT directly reference "user_1" or "user_2" in your responses - instead, refer to them naturally as "you" or "they" based on context.`;
}

// ë¹„íŒ ìƒì„± ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (ì„ íƒëœ ì§„ìˆ ë¬¸ì— ëŒ€í•œ ë¹„íŒ)
async function generateCritiqueResponse(messages: any[], sessionData: any, apiKey: string, endpoint: string, apiVersion: string, modelName: string, roundCount: number) {
  try {
    const systemPrompt = createCritiqueAgentPrompt(sessionData, roundCount);
    
    // ëŒ€í™” ê¸°ë¡ì„ ìž„ì‹œë¡œ ë³µì‚¬í•˜ì—¬ íƒœê·¸ ì œê±° (ì›ë³¸ì€ ë³´ì¡´)
    const tempMessages = messages
      .filter((msg: any) => msg.content !== 'loading' && msg.sender && !msg.hidden)
      .map((msg: any) => {
        if (msg.sender === 'user') {
          return {
            role: 'user',
            content: `user_1: ${msg.content}`
          };
        } else if (msg.content && msg.content.startsWith('@adversarial:')) {
          // ë°˜ëŒ€ ì£¼ìž¥ ì—ì´ì „íŠ¸ì˜ ë°œí™”ë¥¼ user_2ë¡œ í‘œì‹œ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace('@adversarial: ', '');
          return {
            role: 'user',
            content: `user_2: ${contentWithoutTag}`
          };
        } else if (msg.content && msg.content.startsWith('@group-statements:')) {
          // ê·¸ë£¹ ì§„ìˆ ë¬¸ì€ assistantë¡œ ìœ ì§€ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace('@group-statements: ', '');
          return {
            role: 'assistant',
            content: contentWithoutTag
          };
        } else {
          // ê¸°íƒ€ ë©”ì‹œì§€ëŠ” assistantë¡œ ìœ ì§€ (íƒœê·¸ ì œê±°)
          const contentWithoutTag = msg.content.replace(/@(adversarial|group-statements): /, '');
          return {
            role: 'assistant',
            content: contentWithoutTag
          };
        }
      });
    
    // ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    const conversationMessages = [
      {
        role: 'system',
        content: systemPrompt
      },
      ...tempMessages
    ];

    const requestData = {
      messages: conversationMessages,
      model: modelName,
      max_tokens: 800,
      temperature: 0.8 // ë¹„íŒì ì´ê³  ë„ì „ì ì¸ ì‘ë‹µì„ ìœ„í•´ ë†’ì€ temperature
    };

    console.log('Making critique agent API call');
    console.log('=== ORIGINAL MESSAGES (before processing) ===');
    messages?.forEach((msg: any, index: number) => {
      console.log(`Original Message ${index}:`, {
        sender: msg.sender,
        content: msg.content?.substring(0, 100) + (msg.content?.length > 100 ? '...' : ''),
        messageType: msg.messageType
      });
    });
    console.log('=== PROCESSED CONVERSATION MESSAGES ===');
    console.log('Critique agent conversation messages:', JSON.stringify(conversationMessages, null, 2));
    
    const apiUrl = `${endpoint}openai/deployments/${modelName}/chat/completions?api-version=${apiVersion}`;
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'api-key': apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestData)
    });

    console.log('Critique agent API response status:', response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Critique agent API error:', response.status, errorText);
      throw new Error(`API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const rawMessage = data.choices[0]?.message?.content?.trim() || "Looking at this choice, I have some concerns about the selected statement. Let me share my perspective on the implications and potential issues I see with this position.";
    
    // ë¹„íŒ ì—ì´ì „íŠ¸ ì‘ë‹µì— ì ‘ë‘ì‚¬ ì¶”ê°€ (user_2ë¡œ @adversarial íƒœê·¸ ì‚¬ìš©)
    const aiMessage = `@adversarial: ${rawMessage}`;
    
    console.log('Generated critique agent response length:', aiMessage.length);
    
    return new Response(JSON.stringify({ 
      message: aiMessage,
      sessionData: sessionData,
      messageType: 'adversarial-response',
      conversationState: 'conversation_complete', // ëŒ€í™” ì™„ë£Œ ìƒíƒœ
      roundCount: roundCount,
      isFinalResponse: true // ìµœì¢… ì‘ë‹µìž„ì„ í‘œì‹œ
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });

  } catch (error: any) {
    console.error('Critique agent response error:', error);
    
    return new Response(JSON.stringify({ 
      message: "@adversarial: Looking at this choice, I have some concerns about the selected statement. Let me share my perspective on the implications and potential issues I see with this position.",
      sessionData: sessionData,
      messageType: 'adversarial-response',
      conversationState: 'conversation_complete',
      roundCount: roundCount,
      isFinalResponse: true
    }), {
      headers: { 
        'Content-Type': 'application/json',
        ...corsHeaders
      }
    });
  }
}

// ê°„ë‹¨í•œ GET í…ŒìŠ¤íŠ¸ìš©
export const GET: RequestHandler = async () => {
  return new Response('Adversarial Reconciliation Chat API is working!', {
    headers: corsHeaders
  });
};
